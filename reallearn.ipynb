{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from til_environment import gridworld\n",
    "\n",
    "env = gridworld.env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from til_environment import gridworld\n",
    "\n",
    "env = gridworld.env(\n",
    "    env_wrappers=[],  # clear out default env wrappers\n",
    "    render_mode=\"human\",  # Render the map; not visible on Workbench\n",
    "    debug=True,  # Enable debug mode\n",
    "    novice=True,  # Use same map layout every time (for Novice teams only)\n",
    ")\n",
    "env.reset(seed=42)\n",
    "\n",
    "for agent in env.agent_iter():\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "\n",
    "    if termination or truncation:\n",
    "        break\n",
    "    else:\n",
    "        # Insert your policy here\n",
    "        action = env.action_space(agent).sample()\n",
    "\n",
    "    env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "class GymCompatibleEnv(gym.Env):\n",
    "    def __init__(self, pettingzoo_env):\n",
    "        self.env = pettingzoo_env\n",
    "        self.agents = self.env.possible_agents\n",
    "        self.agent = self.agents[0]  # Focus on a single agent for simplicity\n",
    "        self.action_space = self.env.action_space(self.agent)\n",
    "        self.observation_space = self.env.observation_space(self.agent)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        obs = self.env.reset(seed=seed)\n",
    "        return obs[self.agent], {}\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = {agent: self.env.action_space(agent).sample() for agent in self.agents}\n",
    "        actions[self.agent] = action\n",
    "        obs, rewards, terminations, truncations, infos = self.env.step(actions)\n",
    "        return obs[self.agent], rewards[self.agent], terminations[self.agent], truncations[self.agent], infos[self.agent]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
