{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from til_environment import gridworld\n",
    "\n",
    "env = gridworld.env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 4\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 2\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 0\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 3\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n",
      "Action: 1\n",
      "State: Dict('direction': Discrete(4), 'location': Box(0, 16, (2,), uint8), 'scout': Discrete(2), 'step': Discrete(101), 'viewcone': Box(0, 255, (7, 5), uint8))\n"
     ]
    }
   ],
   "source": [
    "from til_environment import gridworld\n",
    "\n",
    "env = gridworld.env(\n",
    "    env_wrappers=[],  # clear out default env wrappers\n",
    "    render_mode=\"human\",  # Render the map; not visible on Workbench\n",
    "    debug=True,  # Enable debug mode\n",
    "    novice=True,  # Use same map layout every time (for Novice teams only)\n",
    ")\n",
    "\n",
    "env.reset(seed=42)\n",
    "score = 0\n",
    "\n",
    "for agent in env.agent_iter():\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "\n",
    "    if termination or truncation:\n",
    "        break\n",
    "    else:\n",
    "        # Insert your policy here\n",
    "        action = env.action_space(agent).sample()\n",
    "        state = env.observation_space(agent)\n",
    "    \n",
    "    score += reward\n",
    "    env.step(action)\n",
    "    print(f\"Action: {action}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "til_env\n"
     ]
    }
   ],
   "source": [
    "# multidiscrete\n",
    "print(env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Baselines 3 PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import gymnasium as gym  # use `import gym` if using gym < 0.26\n",
    "from pettingzoo.utils.env import AECEnv, AgentID, ObsType, ActionType\n",
    "from pettingzoo.utils.wrappers.base import BaseWrapper\n",
    "\n",
    "\n",
    "class CustomWrapper(BaseWrapper[AgentID, ObsType, ActionType], gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, env: AECEnv[AgentID, ObsType, ActionType]):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.agents = self.env.possible_agents\n",
    "        self.current_agent_index = 0\n",
    "        self.current_agent = self.agents[self.current_agent_index]\n",
    "\n",
    "        # Define Gym-style observation/action space\n",
    "        self.observation_space = self.env.observation_space(self.current_agent)\n",
    "        self.action_space = self.env.action_space(self.current_agent)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "\n",
    "        self.current_agent_index = 0\n",
    "        self.current_agent = self.agents[self.current_agent_index]\n",
    "\n",
    "        while self.env.agent_selection != self.current_agent:\n",
    "            self.env.step(None)\n",
    "\n",
    "        obs = self.observe(self.current_agent)\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action: ActionType):\n",
    "        reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        info = {}\n",
    "\n",
    "        self.env.step(action)\n",
    "\n",
    "        reward += self.env.rewards[self.current_agent]\n",
    "        terminated = self.env.terminations[self.current_agent]\n",
    "        truncated = self.env.truncations[self.current_agent]\n",
    "        info = self.env.infos[self.current_agent]\n",
    "\n",
    "        while (\n",
    "            not self.env.terminations[self.current_agent]\n",
    "            and not self.env.truncations[self.current_agent]\n",
    "            and self.env.agent_selection != self.current_agent\n",
    "        ):\n",
    "            self.env.step(None)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        obs = self.observe(self.current_agent)\n",
    "\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        return self.env.render()\n",
    "\n",
    "    def close(self):\n",
    "        return self.env.close()\n",
    "\n",
    "    def observe(self, agent: AgentID) -> ObsType | None:\n",
    "        return super().observe(agent)\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        return super().observation_space(agent)\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def action_space(self, agent):\n",
    "        return super().action_space(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from til_environment.flatten_dict import FlattenDictWrapper\n",
    "from til_environment import gridworld\n",
    "\n",
    "env = gridworld.env(env_wrappers=[CustomWrapper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The environment is of type <class 'pettingzoo.utils.wrappers.order_enforcing.OrderEnforcingWrapper'>, not a Gymnasium environment. In this case, we expect OpenAI Gym to be installed and the environment to be an OpenAI Gym environment.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstable_baselines3\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PPO\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCnnPolicy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m model.learn(total_timesteps=\u001b[32m10000\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:109\u001b[39m, in \u001b[36mPPO.__init__\u001b[39m\u001b[34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     82\u001b[39m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[ActorCriticPolicy]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    108\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43ment_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvf_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvf_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrollout_buffer_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrollout_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrollout_buffer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrollout_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_init_setup_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMultiDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMultiBinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# because of the advantage normalization\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m normalize_advantage:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:86\u001b[39m, in \u001b[36mOnPolicyAlgorithm.__init__\u001b[39m\u001b[34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     63\u001b[39m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[ActorCriticPolicy]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m     supported_action_spaces: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m[spaces.Space], ...]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     85\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_steps = n_steps\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m.gamma = gamma\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/stable_baselines3/common/base_class.py:170\u001b[39m, in \u001b[36mBaseAlgorithm.__init__\u001b[39m\u001b[34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    169\u001b[39m     env = maybe_make_env(env, \u001b[38;5;28mself\u001b[39m.verbose)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     env = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrap_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m.observation_space = env.observation_space\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m.action_space = env.action_space\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/stable_baselines3/common/base_class.py:217\u001b[39m, in \u001b[36mBaseAlgorithm._wrap_env\u001b[39m\u001b[34m(env, verbose, monitor_wrapper)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" \"\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03mWrap environment with the appropriate wrappers if needed.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03mFor instance, to have a vectorized environment\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m \u001b[33;03m:return: The wrapped environment.\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, VecEnv):\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# Patch to support gym 0.21/0.26 and gymnasium\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     env = \u001b[43m_patch_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_wrapped(env, Monitor) \u001b[38;5;129;01mand\u001b[39;00m monitor_wrapper:\n\u001b[32m    219\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m verbose >= \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:33\u001b[39m, in \u001b[36m_patch_env\u001b[39m\u001b[34m(env)\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gym_installed \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, gym.Env):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     34\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe environment is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(env)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, not a Gymnasium \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33menvironment. In this case, we expect OpenAI Gym to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstalled and the environment to be an OpenAI Gym environment.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m     )\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshimmy\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The environment is of type <class 'pettingzoo.utils.wrappers.order_enforcing.OrderEnforcingWrapper'>, not a Gymnasium environment. In this case, we expect OpenAI Gym to be installed and the environment to be an OpenAI Gym environment."
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchRL PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Tensordict modules\n",
    "from tensordict.nn import set_composite_lp_aggregate, TensorDictModule, TensorDictSequential\n",
    "from tensordict import  TensorDictBase\n",
    "from torch import multiprocessing\n",
    "\n",
    "# Data collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torch.distributions import Categorical\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "\n",
    "#Env\n",
    "from torchrl.envs import RewardSum, TransformedEnv, PettingZooWrapper, Compose, DoubleToFloat, StepCounter, ParallelEnv, EnvCreator, ExplorationType, set_exploration_type\n",
    "\n",
    "# Utils\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "\n",
    "# Multi-agent network\n",
    "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
    "\n",
    "# Loss\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "# Utils\n",
    "torch.manual_seed(0)\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import PettingZooWrapper\n",
    "\n",
    "group_map = {\n",
    "    \"scout\": [\"player_0\"],\n",
    "    \"guards\": [\"player_1\", \"player_2\", \"player_3\"]\n",
    "}\n",
    "\n",
    "raw_env = gridworld.env()\n",
    "env = PettingZooWrapper(raw_env, use_mask=True, group_map=group_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#Parameters for Env\n",
    "n_parallel_envs = 2  # Number of parallel environments\n",
    "\n",
    "# Sampling\n",
    "frames_per_batch = 2_000  # Number of team frames collected per training iteration\n",
    "total_frames = 200_000\n",
    "\n",
    "# Training\n",
    "num_epochs = 5  # Number of optimization steps per training iteration\n",
    "minibatch_size = 400  # Size of the mini-batches in each optimization step\n",
    "lr = 3e-4  # Learning rate\n",
    "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "# PPO\n",
    "clip_epsilon = 0.2  # clip value for PPO loss\n",
    "gamma = 0.99  # discount factor\n",
    "lmbda = 0.9  # lambda for generalised advantage estimation\n",
    "entropy_eps = 1e-4  # coefficient of the entropy term in the PPO loss\n",
    "\n",
    "# disable log-prob aggregation\n",
    "set_composite_lp_aggregate(False).set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        guards: TensorDict(\n",
       "            fields={\n",
       "                action: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                mask: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([5, 3, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5, 3]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                guards: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        mask: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([5, 3, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([5, 3]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                scout: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([5, 1]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        scout: TensorDict(\n",
       "            fields={\n",
       "                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5, 1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.rollout(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_names = [\"scout\", \"guards\"]\n",
    "\n",
    "# Create RewardSum transforms for each agent\n",
    "reward_transforms = [\n",
    "    RewardSum(\n",
    "        in_keys=[(agent, \"reward\")],\n",
    "        out_keys=[(agent, \"episode_reward\")]\n",
    "    ) for agent in agent_names\n",
    "]\n",
    "\n",
    "# Compose all transforms\n",
    "env_transforms = Compose(\n",
    "    *reward_transforms,\n",
    "    DoubleToFloat(),\n",
    "    StepCounter()\n",
    ")\n",
    "\n",
    "# Set up the environment creation function\n",
    "make_env = EnvCreator(lambda: TransformedEnv(\n",
    "    PettingZooWrapper(raw_env, use_mask=True, group_map=group_map),  # call raw_env() if it's a function\n",
    "    Compose(\n",
    "    *reward_transforms,\n",
    "    DoubleToFloat(),\n",
    "    StepCounter()\n",
    ")\n",
    "))\n",
    "\n",
    "# Create parallel environments\n",
    "env = ParallelEnv(n_parallel_envs, make_env, serial_for_single=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_names = [\"player_0\", \"player_1\", \"player_2\", \"player_3\"]\n",
    "\n",
    "# Create RewardSum transforms for each agent\n",
    "reward_transforms = [\n",
    "    RewardSum(\n",
    "        in_keys=[(agent, \"reward\")],\n",
    "        out_keys=[(agent, \"episode_reward\")]\n",
    "    ) for agent in agent_names\n",
    "]\n",
    "\n",
    "# Compose all transforms\n",
    "env_transforms = Compose(\n",
    "    *reward_transforms,\n",
    "    DoubleToFloat(),\n",
    "    StepCounter()\n",
    ")\n",
    "\n",
    "# Set up the environment creation function\n",
    "make_env = EnvCreator(lambda: TransformedEnv(\n",
    "    PettingZooWrapper(raw_env, use_mask=True),  # call raw_env() if it's a function\n",
    "    Compose(\n",
    "    *reward_transforms,\n",
    "    DoubleToFloat(),\n",
    "    StepCounter()\n",
    ")\n",
    "))\n",
    "\n",
    "# Create parallel environments\n",
    "check_env = ParallelEnv(n_parallel_envs, make_env, serial_for_single=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n",
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "Process _ProcessNoWarn-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/_utils.py\", line 734, in run\n",
      "    return mp.Process.run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py\", line 2163, in _run_worker_pipe_shared_mem\n",
      "    env = env_fun(**env_fun_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/env_creator.py\", line 203, in __call__\n",
      "    env = self.create_env_fn(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/utils.py\", line 254, in __call__\n",
      "    return self.fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_158934/441793692.py\", line 21, in <lambda>\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 1197, in __init__\n",
      "    t.set_container(self)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 525, in set_container\n",
      "    raise AttributeError(\n",
      "AttributeError: parent of transform <class 'torchrl.envs.transforms.transforms.RewardSum'> already set. Call `transform.clone()` to get a similar transform with no parent set.\n",
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEOFError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[158]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# print(\"action_keys:\", env.action_keys)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# print(\"reward_keys:\", env.reward_keys)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# print(\"done_keys:\", env.done_keys)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# print(\"Reward Spec:\", env.reward_spec)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# print(\"Done Spec:\", env.done_spec)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mcheck_env_specs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_env\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/utils.py:733\u001b[39m, in \u001b[36mcheck_env_specs\u001b[39m\u001b[34m(env, return_contiguous, check_dtype, seed, tensordict)\u001b[39m\n\u001b[32m    731\u001b[39m     fake_tensordict = fake_tensordict.expand(shape)\n\u001b[32m    732\u001b[39m     tensordict = tensordict.expand(shape)\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m real_tensordict = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_contiguous\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_contiguous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n\u001b[32m    741\u001b[39m     fake_tensordict = fake_tensordict.unsqueeze(real_tensordict.batch_dims - \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/common.py:3115\u001b[39m, in \u001b[36mEnvBase.rollout\u001b[39m\u001b[34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[39m\n\u001b[32m   3112\u001b[39m env_device = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m   3114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_reset:\n\u001b[32m-> \u001b[39m\u001b[32m3115\u001b[39m     tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtensordict must be provided when auto_reset is False\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/common.py:2656\u001b[39m, in \u001b[36mEnvBase.reset\u001b[39m\u001b[34m(self, tensordict, **kwargs)\u001b[39m\n\u001b[32m   2652\u001b[39m     tensordict_reset = \u001b[38;5;28mself\u001b[39m._reset(\n\u001b[32m   2653\u001b[39m         tensordict.select(*\u001b[38;5;28mself\u001b[39m.reset_keys, strict=\u001b[38;5;28;01mFalse\u001b[39;00m), **kwargs\n\u001b[32m   2654\u001b[39m     )\n\u001b[32m   2655\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2656\u001b[39m     tensordict_reset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[38;5;66;03m# We assume that this is done properly\u001b[39;00m\n\u001b[32m   2658\u001b[39m \u001b[38;5;66;03m# if reset.device != self.device:\u001b[39;00m\n\u001b[32m   2659\u001b[39m \u001b[38;5;66;03m#     reset = reset.to(self.device, non_blocking=True)\u001b[39;00m\n\u001b[32m   2660\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict_reset \u001b[38;5;129;01mis\u001b[39;00m tensordict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py:63\u001b[39m, in \u001b[36m_check_start.<locals>.decorated_fun\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_closed:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_td()\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ParallelEnv):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py:1458\u001b[39m, in \u001b[36mParallelEnv._start_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28mself\u001b[39m._workers.append(process)\n\u001b[32m   1456\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m parent_pipe \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent_channels:\n\u001b[32m   1457\u001b[39m     \u001b[38;5;66;03m# use msg as sync point\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m     \u001b[43mparent_pipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1460\u001b[39m \u001b[38;5;66;03m# send shared tensordict to workers\u001b[39;00m\n\u001b[32m   1461\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent_channels:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:250\u001b[39m, in \u001b[36m_ConnectionBase.recv\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    249\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(buf.getbuffer())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:399\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m remaining == size:\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgot end of file during message\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mEOFError\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "Process _ProcessNoWarn-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/_utils.py\", line 734, in run\n",
      "    return mp.Process.run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py\", line 2163, in _run_worker_pipe_shared_mem\n",
      "    env = env_fun(**env_fun_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/env_creator.py\", line 203, in __call__\n",
      "    env = self.create_env_fn(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/utils.py\", line 254, in __call__\n",
      "    return self.fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_158934/441793692.py\", line 21, in <lambda>\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 1197, in __init__\n",
      "    t.set_container(self)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 525, in set_container\n",
      "    raise AttributeError(\n",
      "AttributeError: parent of transform <class 'torchrl.envs.transforms.transforms.RewardSum'> already set. Call `transform.clone()` to get a similar transform with no parent set.\n"
     ]
    }
   ],
   "source": [
    "# print(\"action_keys:\", env.action_keys)\n",
    "# print(\"reward_keys:\", env.reward_keys)\n",
    "# print(\"done_keys:\", env.done_keys)\n",
    "\n",
    "# print(\"Action Spec:\", env.action_spec)\n",
    "# print(\"Observation Spec:\", env.observation_spec)\n",
    "# print(\"Reward Spec:\", env.reward_spec)\n",
    "# print(\"Done Spec:\", env.done_spec)\n",
    "\n",
    "check_env_specs(check_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout of 5 steps: TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "                    batch_size=torch.Size([2, 5, 1]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "                    batch_size=torch.Size([2, 5, 1]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                player_2: TensorDict(\n",
      "                    fields={\n",
      "                        done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "                    batch_size=torch.Size([2, 5, 1]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                player_3: TensorDict(\n",
      "                    fields={\n",
      "                        done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                        truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "                    batch_size=torch.Size([2, 5, 1]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                step_count: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([2, 5]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        player_0: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([2, 5, 1]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        player_1: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([2, 5, 1]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        player_2: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([2, 5, 1]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        player_3: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                mask: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([2, 5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([2, 5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([2, 5, 1]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        step_count: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([2, 5]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "Shape of the rollout TensorDict: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "n_rollout_steps = 5\n",
    "rollout = env.rollout(n_rollout_steps)\n",
    "print(f\"rollout of {n_rollout_steps} steps:\", rollout)\n",
    "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedDiscrete(\n",
      "    shape=torch.Size([2, 1, 576]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.int64,\n",
      "    domain=discrete)\n"
     ]
    }
   ],
   "source": [
    "n_player_0 = env.observation_spec[\"player_0\", \"observation\"].shape[1]\n",
    "n_player_1 = env.observation_spec[\"player_1\", \"observation\"].shape[1]\n",
    "n_player_2 = env.observation_spec[\"player_2\", \"observation\"].shape[1]\n",
    "n_player_3 = env.observation_spec[\"player_3\", \"observation\"].shape[1]\n",
    "n_entities = env.observation_spec[\"player_0\", \"observation\"].shape[1]\n",
    "n_features = env.observation_spec[\"player_0\", \"observation\"].shape[2]\n",
    "# n_features = env.observation_spec[\"player_0\", \"observation\"].shape[3]\n",
    "print(env.observation_spec[\"player_0\", \"observation\"])\n",
    "# print(n_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedDiscrete(\n",
      "    shape=torch.Size([2, 1, 576]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.int64,\n",
      "    domain=discrete)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_spec[\"player_3\", \"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flattening module that handles the batched_env+time dimensions\n",
    "class FlattenObs(nn.Module):\n",
    "    def forward(self, obs):\n",
    "        # Convert to float first\n",
    "        obs = obs.float()\n",
    "\n",
    "        # Handle different possible shapes\n",
    "        if len(obs.shape) == 5:  # [batch_env, time, n_agents, n_entities, n_features]\n",
    "            batch_env, time, n_agents, n_entities, n_features = obs.shape\n",
    "\n",
    "            # Reshape to merge batch_env and time dimensions\n",
    "            # This gives [batch_env*time, n_agents, n_entities, n_features]\n",
    "            obs = obs.reshape(-1, n_agents, n_entities, n_features)\n",
    "\n",
    "            # Take only the first entity for each agent (agent itself)\n",
    "            return obs[:, :, 0, :]  # [batch_env*time, n_agents, n_features]\n",
    "\n",
    "        elif len(obs.shape) == 4:  # [batch, n_agents, n_entities, n_features]\n",
    "            batch, n_agents, n_entities, n_features = obs.shape\n",
    "            return obs[:, :, 0, :]  # [batch, n_agents, n_features]\n",
    "\n",
    "        elif len(obs.shape) == 3:  # [batch, n_entities, n_features]\n",
    "              batch, n_entities, n_features = obs.shape\n",
    "              return obs.reshape(batch, n_entities * n_features)\n",
    "\n",
    "        # Fallback for unexpected shapes\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_modules = {}\n",
    "critics = {}\n",
    "\n",
    "obs_dim = 576\n",
    "n_actions = 5\n",
    "\n",
    "# Scout policy (player_0)\n",
    "policy_mlp_scout = MultiAgentMLP(\n",
    "    n_agent_inputs=obs_dim,\n",
    "    n_agent_outputs=n_actions,\n",
    "    n_agents=1,  # 1 scout\n",
    "    centralised=False,\n",
    "    share_params=True,\n",
    "    device=device,\n",
    "    depth=2,\n",
    "    num_cells=256,\n",
    "    activation_class=nn.Tanh,\n",
    ")\n",
    "\n",
    "# Guards policy (players 1-3)\n",
    "policy_mlp_guard = MultiAgentMLP(\n",
    "    n_agent_inputs=obs_dim,\n",
    "    n_agent_outputs=n_actions,\n",
    "    n_agents=3,  # 3 guards\n",
    "    centralised=False,\n",
    "    share_params=True,  # Share params among guards\n",
    "    device=device,\n",
    "    depth=2,\n",
    "    num_cells=256,\n",
    "    activation_class=nn.Tanh,\n",
    ")\n",
    "\n",
    "# Create sequential modules with flattening if needed\n",
    "policy_seq_scout = nn.Sequential(policy_mlp_scout, nn.Softmax(dim=-1))\n",
    "policy_seq_guard = nn.Sequential(policy_mlp_guard, nn.Softmax(dim=-1))\n",
    "\n",
    "# Wrap in TensorDictModule\n",
    "policy_modules[\"player_0\"] = TensorDictModule(\n",
    "    module=policy_seq_scout,\n",
    "    in_keys=[(\"player_0\", \"observation\")],\n",
    "    out_keys=[(\"player_0\", \"probs\")]\n",
    ")\n",
    "\n",
    "for i in range(1, 4):\n",
    "    policy_modules[f\"player_{i}\"] = TensorDictModule(\n",
    "        module=policy_seq_guard,\n",
    "        in_keys=[(f\"player_{i}\", \"observation\")],\n",
    "        out_keys=[(f\"player_{i}\", \"probs\")]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedDiscrete(\n",
      "    shape=torch.Size([2, 1, 576]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.int64,\n",
      "    domain=discrete)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_spec[\"player_2\", \"observation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scout critic\n",
    "MAPPO = True\n",
    "\n",
    "critic_module_scout = TensorDictModule(\n",
    "    module=MultiAgentMLP(\n",
    "        n_agent_inputs=obs_dim,\n",
    "        n_agent_outputs=1,\n",
    "        n_agents=1,\n",
    "        centralised=MAPPO,  # True for MAPPO, False for IPPO\n",
    "        share_params=True,\n",
    "        device=device,\n",
    "        activation_class=nn.Tanh,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "    ),\n",
    "    in_keys=[(\"player_0\", \"observation\")],\n",
    "    out_keys=[(\"player_0\", \"state_value\")]\n",
    ")\n",
    "\n",
    "# Guards critic\n",
    "critic_module_guard = TensorDictModule(\n",
    "    module=MultiAgentMLP(\n",
    "        n_agent_inputs=obs_dim,\n",
    "        n_agent_outputs=1,\n",
    "        n_agents=3,\n",
    "        centralised=MAPPO,  # True for MAPPO, False for IPPO\n",
    "        share_params=True,  # Share among guards\n",
    "        device=device,\n",
    "        activation_class=nn.Tanh,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "    ),\n",
    "    in_keys=[(\"player_1\", \"observation\")],  # Will be applied to all guards\n",
    "    out_keys=[(\"player_1\", \"state_value\")]\n",
    ")\n",
    "\n",
    "critics[\"player_0\"] = critic_module_scout\n",
    "\n",
    "# Use same critic for all guards\n",
    "for i in range(1, 4):\n",
    "    critics[f\"player_{i}\"] = critic_module_guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = {}\n",
    "for i in range(4):\n",
    "    player = f\"player_{i}\"\n",
    "    policies[player] = ProbabilisticActor(\n",
    "        module=policy_modules[player],\n",
    "        spec=env.action_spec[player, \"action\"],\n",
    "        in_keys=[(player, \"probs\")],\n",
    "        out_keys=[(player, \"action\")],\n",
    "        distribution_class=Categorical,\n",
    "        return_log_prob=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed while executing module '0'. Scroll up for more info.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: TensorDictModule failed with operation\n    Sequential(\n      (0): MultiAgentMLP(\n          MLP(\n            (0): Linear(in_features=576, out_features=256, bias=True)\n            (1): Tanh()\n            (2): Linear(in_features=256, out_features=256, bias=True)\n            (3): Tanh()\n            (4): Linear(in_features=256, out_features=5, bias=True)\n          ),\n          n_agents=1,\n          share_params=True,\n          centralized=False,\n          agent_dim=-2)\n      (1): Softmax(dim=-1)\n    )\n    in_keys=[('player_0', 'observation')]\n    out_keys=[('player_0', 'probs')].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:564\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:518\u001b[39m, in \u001b[36mTensorDictSequential._run_module\u001b[39m\u001b[34m(self, module, tensordict, **kwargs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    516\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensordict.keys(include_nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.in_keys\n\u001b[32m    517\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     tensordict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:327\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:1187\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1186\u001b[39m out_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.out_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1187\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1188\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1189\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:1159\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1161\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensors_out \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_keys\n\u001b[32m   1162\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:1143\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1143\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:1109\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_module\u001b[39m(\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28mself\u001b[39m, tensors: Sequence[Tensor], **kwargs: Any\n\u001b[32m   1108\u001b[39m ) -> Tensor | Sequence[Tensor]:\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/modules/models/multiagent.py:156\u001b[39m, in \u001b[36mMultiAgentNetBase.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params.to_module(\u001b[38;5;28mself\u001b[39m._empty_net):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_empty_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.centralized:\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# If the parameters are shared, and it is centralized, all agents will have the same output\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# We expand it to maintain the agent dimension, but values will be the same for all agents\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/modules/models/models.py:300\u001b[39m, in \u001b[36mMLP.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m    298\u001b[39m     inputs = (torch.cat([*inputs], -\u001b[32m1\u001b[39m),)\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m out = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reshape_out:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 must have the same dtype, but got Long and Float",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:564\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:518\u001b[39m, in \u001b[36mTensorDictSequential._run_module\u001b[39m\u001b[34m(self, module, tensordict, **kwargs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    516\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensordict.keys(include_nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.in_keys\n\u001b[32m    517\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     tensordict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:327\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/probabilistic.py:1318\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1318\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1319\u001b[39m     tensordict_exec = \u001b[38;5;28mself\u001b[39m._last_module(\n\u001b[32m   1320\u001b[39m         tensordict_exec, _requires_sample=\u001b[38;5;28mself\u001b[39m._requires_sample\n\u001b[32m   1321\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/probabilistic.py:1072\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.get_dist_params\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:327\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:569\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m             module_num_or_key = \u001b[38;5;28mself\u001b[39m._get_module_num_or_key(module)\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    570\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed while executing module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_num_or_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Scroll up for more info.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    571\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed while executing module '0'. Scroll up for more info.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m agents_policy = TensorDictSequential(*policies.values())\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Or if you have a separate policies dictionary:\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# agents_policy = TensorDictSequential(*policies.values())\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create the collector with the sequential policy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m collector = \u001b[43mSyncDataCollector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43magents_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstoring_device\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/collectors/collectors.py:764\u001b[39m, in \u001b[36mSyncDataCollector.__init__\u001b[39m\u001b[34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, policy_device, env_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, return_same_td, reset_when_done, interruptor, set_truncated, use_buffers, replay_buffer, trust_policy, compile_policy, cudagraph_policy, no_cuda_sync, **kwargs)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28mself\u001b[39m._make_shuttle()\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_buffers:\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_final_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[38;5;28mself\u001b[39m._set_truncated_keys()\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m split_trajs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/collectors/collectors.py:860\u001b[39m, in \u001b[36mSyncDataCollector._make_final_rollout\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compiled_policy:\n\u001b[32m    859\u001b[39m     cudagraph_mark_step_begin()\n\u001b[32m--> \u001b[39m\u001b[32m860\u001b[39m policy_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;66;03m# check that we don't have exclusive keys, because they don't appear in keys\u001b[39;00m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_exclusive\u001b[39m(val):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/common.py:327\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    375\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:569\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    568\u001b[39m             module_num_or_key = \u001b[38;5;28mself\u001b[39m._get_module_num_or_key(module)\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    570\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed while executing module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_num_or_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Scroll up for more info.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    571\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictSequential does not support keyword arguments other than \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtensordict_out\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or in_keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs.keys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed while executing module '0'. Scroll up for more info."
     ]
    }
   ],
   "source": [
    "# Convert the policy dictionary to a sequential policy for the collector\n",
    "\n",
    "# If you're using the actors dictionary as your policy:\n",
    "agents_policy = TensorDictSequential(*policies.values())\n",
    "\n",
    "# Or if you have a separate policies dictionary:\n",
    "# agents_policy = TensorDictSequential(*policies.values())\n",
    "\n",
    "# Create the collector with the sequential policy\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    agents_policy,\n",
    "    device=device,\n",
    "    storing_device=device,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=total_frames,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent groups manually\n",
    "groups = [\"archer\", \"knight\"]\n",
    "\n",
    "# Create separate replay buffers for each group\n",
    "replay_buffers = {}\n",
    "for group in groups: \n",
    "    replay_buffers[group] = ReplayBuffer(\n",
    "        storage=LazyTensorStorage(\n",
    "            frames_per_batch, device=device\n",
    "        ),\n",
    "        sampler=SamplerWithoutReplacement(),\n",
    "        batch_size=minibatch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch: TensorDictBase) -> TensorDictBase:\n",
    "    \"\"\"Expand done and terminated keys for each group to match reward shape.\"\"\"\n",
    "    for i in range(4):\n",
    "        player = f\"player_{i}\"\n",
    "        keys = list(batch.keys(True, True))\n",
    "        group_shape = batch.get_item_shape(player)\n",
    "        nested_done_key = (\"next\", player, \"done\")\n",
    "        nested_terminated_key = (\"next\", player, \"terminated\")\n",
    "        if nested_done_key not in keys:\n",
    "            batch.set(\n",
    "                nested_done_key,\n",
    "                batch.get((\"next\", \"done\")).unsqueeze(-1).expand((*group_shape, 1)),\n",
    "            )\n",
    "        if nested_terminated_key not in keys:\n",
    "            batch.set(\n",
    "                nested_terminated_key,\n",
    "                batch.get((\"next\", \"terminated\"))\n",
    "                .unsqueeze(-1)\n",
    "                .expand((*group_shape, 1)),\n",
    "            )\n",
    "    return batch\n",
    "\n",
    "# Training loop\n",
    "groups = [f\"player_{i}\" for i in range(4)]  # All 4 players\n",
    "episode_reward_mean_map = {group: [] for group in groups}\n",
    "\n",
    "for iteration, batch in enumerate(collector):\n",
    "    batch = process_batch(batch)\n",
    "    \n",
    "    # Process each player\n",
    "    for group in groups:\n",
    "        # Extract data for this player only\n",
    "        group_batch = batch.exclude(\n",
    "            *[\n",
    "                key\n",
    "                for player in groups\n",
    "                if player != group\n",
    "                for key in [player, (\"next\", player)]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Reshape and add to replay buffer\n",
    "        group_batch = group_batch.reshape(-1)\n",
    "        replay_buffers[group].extend(group_batch)\n",
    "        \n",
    "        # PPO training epochs\n",
    "        for _ in range(num_epochs):\n",
    "            for subdata in replay_buffers[group]:\n",
    "                loss_vals = losses[group](subdata)\n",
    "                loss_value = (\n",
    "                    loss_vals[\"loss_objective\"] +\n",
    "                    loss_vals[\"loss_critic\"] +\n",
    "                    loss_vals[\"loss_entropy\"]\n",
    "                )\n",
    "                \n",
    "                optimizers[group].zero_grad()\n",
    "                loss_value.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    losses[group].parameters(), max_grad_norm\n",
    "                )\n",
    "                optimizers[group].step()\n",
    "    \n",
    "    # Update policy weights\n",
    "    collector.update_policy_weights_()\n",
    "    \n",
    "    # Logging\n",
    "    for group in groups:\n",
    "        done_mask = batch.get((\"next\", group, \"done\"))\n",
    "        if done_mask.any():\n",
    "            episode_reward_mean = (\n",
    "                batch.get((\"next\", group, \"episode_reward\"))[done_mask]\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "        else:\n",
    "            episode_reward_mean = (\n",
    "                episode_reward_mean_map[group][-1] if episode_reward_mean_map[group] else 0.0\n",
    "            )\n",
    "        episode_reward_mean_map[group].append(episode_reward_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'raw_env' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m env = \u001b[43mTransformedEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# normalize observations\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mObservationNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobservation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mDoubleToFloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mStepCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py:662\u001b[39m, in \u001b[36m_TEnvPostInit.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m     instance: EnvBase = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_EnvPostInit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m     \u001b[38;5;66;03m# we skip the materialization of the specs, because this can't be done with lazy\u001b[39;00m\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# transforms such as ObservationNorm.\u001b[39;00m\n\u001b[32m    665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py:715\u001b[39m, in \u001b[36mTransformedEnv.__init__\u001b[39m\u001b[34m(self, env, transform, cache_specs, **kwargs)\u001b[39m\n\u001b[32m    713\u001b[39m     env = env.to(device)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     device = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(device=\u001b[38;5;28;01mNone\u001b[39;00m, allow_done_after_reset=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs)\n\u001b[32m    718\u001b[39m \u001b[38;5;66;03m# Type matching must be exact here, because subtyping could introduce differences in behavior that must\u001b[39;00m\n\u001b[32m    719\u001b[39m \u001b[38;5;66;03m# be contained within the subclass.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/pettingzoo/utils/wrappers/order_enforcing.py:55\u001b[39m, in \u001b[36mOrderEnforcingWrapper.__getattr__\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m     42\u001b[39m     value\n\u001b[32m     43\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset\n\u001b[32m     53\u001b[39m ):\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be accessed before reset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/pettingzoo/utils/wrappers/base.py:25\u001b[39m, in \u001b[36mBaseWrapper.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name != \u001b[33m\"\u001b[39m\u001b[33m_cumulative_rewards\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maccessing private attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is prohibited\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/pettingzoo/utils/wrappers/base.py:25\u001b[39m, in \u001b[36mBaseWrapper.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name != \u001b[33m\"\u001b[39m\u001b[33m_cumulative_rewards\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maccessing private attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is prohibited\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/pettingzoo/utils/wrappers/order_enforcing.py:55\u001b[39m, in \u001b[36mOrderEnforcingWrapper.__getattr__\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m     42\u001b[39m     value\n\u001b[32m     43\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset\n\u001b[32m     53\u001b[39m ):\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be accessed before reset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/pettingzoo/utils/wrappers/base.py:25\u001b[39m, in \u001b[36mBaseWrapper.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name != \u001b[33m\"\u001b[39m\u001b[33m_cumulative_rewards\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maccessing private attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is prohibited\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/pettingzoo/utils/wrappers/base.py:25\u001b[39m, in \u001b[36mBaseWrapper.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name != \u001b[33m\"\u001b[39m\u001b[33m_cumulative_rewards\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maccessing private attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is prohibited\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'raw_env' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "env = TransformedEnv(\n",
    "    raw_env,\n",
    "    Compose(\n",
    "        # normalize observations\n",
    "        ObservationNorm(in_keys=[\"observation\"]),\n",
    "        DoubleToFloat(),\n",
    "        StepCounter(),\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolicyNetwork' object has no attribute 'log_prob_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m optimizer = Adam(\u001b[38;5;28mlist\u001b[39m(policy_net.parameters()) + \u001b[38;5;28mlist\u001b[39m(value_net.parameters()), lr=\u001b[32m3e-4\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Define PPO loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m loss_fn = \u001b[43mClipPPOLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_net\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/objectives/ppo.py:910\u001b[39m, in \u001b[36mClipPPOLoss.__init__\u001b[39m\u001b[34m(self, actor_network, critic_network, clip_epsilon, entropy_bonus, samples_mc_entropy, entropy_coef, critic_coef, loss_critic_type, normalize_advantage, normalize_advantage_exclude_dims, gamma, separate_losses, reduction, clip_value, **kwargs)\u001b[39m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clip_value, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    908\u001b[39m     clip_value = clip_epsilon \u001b[38;5;28;01mif\u001b[39;00m clip_value \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mClipPPOLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_network\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_network\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentropy_bonus\u001b[49m\u001b[43m=\u001b[49m\u001b[43mentropy_bonus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m    \u001b[49m\u001b[43msamples_mc_entropy\u001b[49m\u001b[43m=\u001b[49m\u001b[43msamples_mc_entropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentropy_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mentropy_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcritic_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_critic_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_critic_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_advantage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize_advantage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_advantage_exclude_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize_advantage_exclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparate_losses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparate_losses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameters():\n\u001b[32m    927\u001b[39m     device = p.device\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/objectives/ppo.py:430\u001b[39m, in \u001b[36mPPOLoss.__init__\u001b[39m\u001b[34m(self, actor_network, critic_network, entropy_bonus, samples_mc_entropy, entropy_coef, critic_coef, loss_critic_type, normalize_advantage, normalize_advantage_exclude_dims, gamma, separate_losses, advantage_key, value_target_key, value_key, functional, actor, critic, reduction, clip_value, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    427\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclip_value must be a float or a scalar tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclip_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         )\n\u001b[32m    429\u001b[39m \u001b[38;5;28mself\u001b[39m.register_buffer(\u001b[33m\"\u001b[39m\u001b[33mclip_value\u001b[39m\u001b[33m\"\u001b[39m, clip_value)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m log_prob_keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactor_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob_keys\u001b[49m\n\u001b[32m    431\u001b[39m action_keys = \u001b[38;5;28mself\u001b[39m.actor_network.dist_sample_keys\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(log_prob_keys) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'PolicyNetwork' object has no attribute 'log_prob_keys'"
     ]
    }
   ],
   "source": [
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "obs_dim = 4\n",
    "action_dim = 5\n",
    "\n",
    "# Initialize networks\n",
    "policy_net = PolicyNetwork(obs_dim, action_dim)\n",
    "value_net = ValueNetwork(obs_dim)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = Adam(list(policy_net.parameters()) + list(value_net.parameters()), lr=3e-4)\n",
    "\n",
    "# Define PPO loss\n",
    "loss_fn = ClipPPOLoss(policy_net, value_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(num_episodes):\n",
    "    obs = wrapped_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Select action using policy network\n",
    "        action = policy_net(obs)\n",
    "        # Step the environment\n",
    "        next_obs, reward, done, info = wrapped_env.step(action)\n",
    "        # Compute loss and update networks\n",
    "        loss = loss_fn(obs, action, reward, next_obs, done)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        obs = next_obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Second argument must be callable.', <pettingzoo.utils.wrappers.order_enforcing.OrderEnforcingWrapper object at 0x710749eb2fc0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tune\n\u001b[32m      5\u001b[39m raw_env = gridworld.env()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mregister_env\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy_env\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m config = (\n\u001b[32m      9\u001b[39m     PPOConfig()\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Set the config object's env.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     )\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m tune.Tuner(\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPPO\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     run_config=tune.RunConfig(stop={\u001b[33m\"\u001b[39m\u001b[33mtraining_iteration\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m}),\n\u001b[32m     21\u001b[39m     param_space=config,\n\u001b[32m     22\u001b[39m ).fit()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/ray/tune/registry.py:137\u001b[39m, in \u001b[36mregister_env\u001b[39m\u001b[34m(name, env_creator)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Register a custom environment for use with RLlib.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03mThis enables the environment to be accessed on every Ray process\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    133\u001b[39m \u001b[33;03m    env_creator: Callable that creates an env.\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(env_creator):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSecond argument must be callable.\u001b[39m\u001b[33m\"\u001b[39m, env_creator)\n\u001b[32m    138\u001b[39m _global_registry.register(ENV_CREATOR, name, env_creator)\n",
      "\u001b[31mTypeError\u001b[39m: ('Second argument must be callable.', <pettingzoo.utils.wrappers.order_enforcing.OrderEnforcingWrapper object at 0x710749eb2fc0>)"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.registry import register_env\n",
    "from ray import tune\n",
    "\n",
    "raw_env = gridworld.env()\n",
    "register_env(\"my_env\", raw_env)\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    # Set the config object's env.\n",
    "    .environment(env=\"my_env\")\n",
    "    # Update the config object's training parameters.\n",
    "    .training(\n",
    "        lr=0.001, clip_param=0.2\n",
    "    )\n",
    ")\n",
    "\n",
    "tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=tune.RunConfig(stop={\"training_iteration\": 1}),\n",
    "    param_space=config,\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 10:04:40.196828: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-03 10:04:40.205249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748916280.214868   74622 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748916280.217930   74622 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748916280.227155   74622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748916280.227168   74622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748916280.227169   74622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748916280.227170   74622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-03 10:04:40.230863: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1, states)))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='relu'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_channels=7, input_dim=35, hidden_dim=128, depth=2):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.ModuleList()\n",
    "        \n",
    "        # Determine per-channel output dim such that total is close to hidden_dim\n",
    "        per_channel_dim = hidden_dim // input_channels\n",
    "        \n",
    "        for _ in range(input_channels):\n",
    "            layers = []\n",
    "            dim = input_dim\n",
    "            for _ in range(depth - 1):\n",
    "                layers.append(nn.Linear(dim, per_channel_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                dim = per_channel_dim\n",
    "            # Ensure the final layer matches per_channel_dim (in case depth=1)\n",
    "            layers.append(nn.Linear(dim, per_channel_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            self.feature_extractor.append(nn.Sequential(*layers))\n",
    "\n",
    "        # The concatenated feature will have dimension input_channels * per_channel_dim ≈ hidden_dim\n",
    "        self.fc = nn.Linear(input_channels * per_channel_dim, hidden_dim)\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(depth):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, input_channels, input_dim]\n",
    "        features = [self.feature_extractor[i](x[:, i, :]) for i in range(len(self.feature_extractor))]\n",
    "        x = torch.cat(features, dim=-1)\n",
    "        x = self.fc(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class ActorHead(nn.Module):\n",
    "    def __init__(self, hidden_dim, action_space, depth):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = hidden_dim\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = hidden_dim\n",
    "        # Final layer outputs logits over actions\n",
    "        layers.append(nn.Linear(in_dim, action_space))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, input_channels, input_dim, hidden_dim, depth, action_space, temperature):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(\n",
    "                        input_channels=input_channels,\n",
    "                        input_dim=input_dim,\n",
    "                        hidden_dim=hidden_dim,\n",
    "                        depth=depth\n",
    "                        )\n",
    "        self.actor = ActorHead(\n",
    "                        hidden_dim=hidden_dim,\n",
    "                        action_space=action_space,\n",
    "                        depth=depth)\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self, x, deterministic=False):\n",
    "        encoded = self.encoder(x)     \n",
    "        logits = self.actor(encoded)             \n",
    "        if deterministic:\n",
    "            action = torch.argmax(logits, dim=-1)  # Choose most probable action          \n",
    "        else:      \n",
    "            scaled_logits = logits / self.temperature\n",
    "            dist = Categorical(logits=scaled_logits)\n",
    "            action = dist.sample()                   \n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from pettingzoo.utils.env import ActionType, AECEnv, AgentID, ObsType\n",
    "from pettingzoo.utils.wrappers.base import BaseWrapper\n",
    "\n",
    "class CustomWrapper(BaseWrapper[AgentID, ObsType, ActionType]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: AECEnv[AgentID, ObsType, ActionType],\n",
    "    ):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed, options)\n",
    "\n",
    "    def step(self, action: ActionType):\n",
    "        super().step(action)\n",
    "\n",
    "    def observe(self, agent: AgentID) -> ObsType | None:\n",
    "        obs = super().observe(agent)\n",
    "        return obs\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        space = super().observation_space(agent)\n",
    "        return space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
