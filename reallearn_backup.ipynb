{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from til_environment import gridworld\n",
    "\n",
    "env = gridworld.env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Tensordict modules\n",
    "from tensordict.nn import set_composite_lp_aggregate, TensorDictModule, TensorDictSequential\n",
    "from tensordict import  TensorDictBase\n",
    "from torch import multiprocessing\n",
    "\n",
    "# Data collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torch.distributions import Categorical\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "\n",
    "#Env\n",
    "from torchrl.envs import RewardSum, TransformedEnv, PettingZooWrapper, Compose, DoubleToFloat, StepCounter, ParallelEnv, EnvCreator, ExplorationType, set_exploration_type\n",
    "\n",
    "# Utils\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "\n",
    "# Multi-agent network\n",
    "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
    "\n",
    "# Loss\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "# Utils\n",
    "torch.manual_seed(0)\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import PettingZooWrapper\n",
    "\n",
    "group_map = {\n",
    "    \"scout\": [\"player_0\"],\n",
    "    \"guards\": [\"player_1\", \"player_2\", \"player_3\"]\n",
    "}\n",
    "\n",
    "raw_env = gridworld.env()\n",
    "env = PettingZooWrapper(raw_env, use_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                player_0: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([5, 1]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                player_1: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([5, 1]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                player_2: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([5, 1]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                player_3: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([5, 1]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        player_0: TensorDict(\n",
       "            fields={\n",
       "                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5, 1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        player_1: TensorDict(\n",
       "            fields={\n",
       "                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5, 1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        player_2: TensorDict(\n",
       "            fields={\n",
       "                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5, 1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        player_3: TensorDict(\n",
       "            fields={\n",
       "                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                mask: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([5, 1, 576]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([5, 1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.rollout(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#Parameters for Env\n",
    "n_parallel_envs = 2  # Number of parallel environments\n",
    "\n",
    "# Sampling\n",
    "frames_per_batch = 2_000  # Number of team frames collected per training iteration\n",
    "total_frames = 200_000\n",
    "\n",
    "# Training\n",
    "num_epochs = 5  # Number of optimization steps per training iteration\n",
    "minibatch_size = 400  # Size of the mini-batches in each optimization step\n",
    "lr = 3e-4  # Learning rate\n",
    "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "# PPO\n",
    "clip_epsilon = 0.2  # clip value for PPO loss\n",
    "gamma = 0.99  # discount factor\n",
    "lmbda = 0.9  # lambda for generalised advantage estimation\n",
    "entropy_eps = 1e-4  # coefficient of the entropy term in the PPO loss\n",
    "\n",
    "# disable log-prob aggregation\n",
    "set_composite_lp_aggregate(False).set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Player_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     12\u001b[39m env_transforms = Compose(\n\u001b[32m     13\u001b[39m     *reward_transforms,\n\u001b[32m     14\u001b[39m     DoubleToFloat(),\n\u001b[32m     15\u001b[39m     StepCounter()\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Set up the environment creation function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m make_env = \u001b[43mEnvCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTransformedEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPettingZooWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# call raw_env() if it's a function\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mreward_transforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDoubleToFloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mStepCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Create parallel environments\u001b[39;00m\n\u001b[32m     29\u001b[39m env = ParallelEnv(n_parallel_envs, make_env, serial_for_single=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/env_creator.py:98\u001b[39m, in \u001b[36mEnvCreator.__init__\u001b[39m\u001b[34m(self, create_env_fn, create_env_kwargs, share_memory, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._meta_data = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m._share_memory = share_memory\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/env_creator.py:174\u001b[39m, in \u001b[36mEnvCreator.init_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> EnvCreator:\n\u001b[32m    173\u001b[39m     shadow_env = \u001b[38;5;28mself\u001b[39m.create_env_fn(**\u001b[38;5;28mself\u001b[39m.create_env_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     tensordict = \u001b[43mshadow_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     shadow_env.rand_step(tensordict)\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.env_type = \u001b[38;5;28mtype\u001b[39m(shadow_env)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/common.py:2656\u001b[39m, in \u001b[36mEnvBase.reset\u001b[39m\u001b[34m(self, tensordict, **kwargs)\u001b[39m\n\u001b[32m   2652\u001b[39m     tensordict_reset = \u001b[38;5;28mself\u001b[39m._reset(\n\u001b[32m   2653\u001b[39m         tensordict.select(*\u001b[38;5;28mself\u001b[39m.reset_keys, strict=\u001b[38;5;28;01mFalse\u001b[39;00m), **kwargs\n\u001b[32m   2654\u001b[39m     )\n\u001b[32m   2655\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2656\u001b[39m     tensordict_reset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[38;5;66;03m# We assume that this is done properly\u001b[39;00m\n\u001b[32m   2658\u001b[39m \u001b[38;5;66;03m# if reset.device != self.device:\u001b[39;00m\n\u001b[32m   2659\u001b[39m \u001b[38;5;66;03m#     reset = reset.to(self.device, non_blocking=True)\u001b[39;00m\n\u001b[32m   2660\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict_reset \u001b[38;5;129;01mis\u001b[39;00m tensordict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py:961\u001b[39m, in \u001b[36mTransformedEnv._reset\u001b[39m\u001b[34m(self, tensordict, **kwargs)\u001b[39m\n\u001b[32m    959\u001b[39m     tensordict = tensordict_reset.empty()\n\u001b[32m    960\u001b[39m \u001b[38;5;28mself\u001b[39m.base_env._complete_done(\u001b[38;5;28mself\u001b[39m.base_env.full_done_spec, tensordict_reset)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m tensordict_reset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_reset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensordict_reset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py:1300\u001b[39m, in \u001b[36mCompose._reset\u001b[39m\u001b[34m(self, tensordict, tensordict_reset)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reset\u001b[39m(\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28mself\u001b[39m, tensordict: TensorDictBase, tensordict_reset: TensorDictBase\n\u001b[32m   1298\u001b[39m ) -> TensorDictBase:\n\u001b[32m   1299\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m-> \u001b[39m\u001b[32m1300\u001b[39m         tensordict_reset = \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_reset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict_reset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py:6731\u001b[39m, in \u001b[36mRewardSum._reset\u001b[39m\u001b[34m(self, tensordict, tensordict_reset)\u001b[39m\n\u001b[32m   6729\u001b[39m value = tensordict.get(out_key, default=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   6730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6731\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfull_reward_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[43min_key\u001b[49m\u001b[43m]\u001b[49m.zero()\n\u001b[32m   6732\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6733\u001b[39m     value = torch.where(expand_as_right(~_reset, value), value, \u001b[32m0.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/tensor_specs.py:4755\u001b[39m, in \u001b[36mComposite.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m   4753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx_unravel:\n\u001b[32m   4754\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx_unravel, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4755\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[idx[\u001b[32m1\u001b[39m:]]\n\u001b[32m   4756\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m idx_unravel \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mspace\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m   4757\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComposite has no key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx_unravel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/tensor_specs.py:4758\u001b[39m, in \u001b[36mComposite.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m   4756\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m idx_unravel \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mspace\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m   4757\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComposite has no key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx_unravel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_specs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_unravel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   4760\u001b[39m indexed_shape = _shape_indexing(\u001b[38;5;28mself\u001b[39m.shape, idx)\n\u001b[32m   4761\u001b[39m indexed_specs = {}\n",
      "\u001b[31mKeyError\u001b[39m: 'Player_0'"
     ]
    }
   ],
   "source": [
    "agent_names = [\"player_0\", \"player_1\", \"player_2\", \"player_3\"]\n",
    "\n",
    "# Create RewardSum transforms for each agent\n",
    "reward_transforms = [\n",
    "    RewardSum(\n",
    "        in_keys=[(agent, \"reward\")],\n",
    "        out_keys=[(agent, \"episode_reward\")]\n",
    "    ) for agent in agent_names\n",
    "]\n",
    "\n",
    "# Compose all transforms\n",
    "env_transforms = Compose(\n",
    "    *reward_transforms,\n",
    "    DoubleToFloat(),\n",
    "    StepCounter()\n",
    ")\n",
    "\n",
    "# Set up the environment creation function\n",
    "make_env = EnvCreator(lambda: TransformedEnv(\n",
    "    PettingZooWrapper(raw_env, use_mask=True),  # call raw_env() if it's a function\n",
    "    Compose(\n",
    "    *reward_transforms,\n",
    "    DoubleToFloat(),\n",
    "    StepCounter()\n",
    ")\n",
    "))\n",
    "\n",
    "# Create parallel environments\n",
    "env = ParallelEnv(n_parallel_envs, make_env, serial_for_single=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_keys: [('player_0', 'action'), ('player_1', 'action'), ('player_2', 'action'), ('player_3', 'action')]\n",
      "reward_keys: [('player_0', 'reward'), ('player_1', 'reward'), ('player_2', 'reward'), ('player_3', 'reward')]\n",
      "done_keys: ['done', 'terminated', 'truncated', ('player_0', 'done'), ('player_0', 'terminated'), ('player_0', 'truncated'), ('player_1', 'done'), ('player_1', 'terminated'), ('player_1', 'truncated'), ('player_2', 'done'), ('player_2', 'terminated'), ('player_2', 'truncated'), ('player_3', 'done'), ('player_3', 'terminated'), ('player_3', 'truncated')]\n",
      "Action Spec: Composite(\n",
      "    player_0: Composite(\n",
      "        action: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=5),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_1: Composite(\n",
      "        action: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=5),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_2: Composite(\n",
      "        action: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=5),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_3: Composite(\n",
      "        action: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=5),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([2]))\n",
      "Observation Spec: Composite(\n",
      "    player_0: Composite(\n",
      "        observation: BoundedDiscrete(\n",
      "            shape=torch.Size([2, 1, 576]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        mask: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        episode_reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_1: Composite(\n",
      "        observation: BoundedDiscrete(\n",
      "            shape=torch.Size([2, 1, 576]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        mask: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        episode_reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_2: Composite(\n",
      "        observation: BoundedDiscrete(\n",
      "            shape=torch.Size([2, 1, 576]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        mask: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        episode_reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_3: Composite(\n",
      "        observation: BoundedDiscrete(\n",
      "            shape=torch.Size([2, 1, 576]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 576]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        mask: Categorical(\n",
      "            shape=torch.Size([2, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        episode_reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    step_count: BoundedDiscrete(\n",
      "        shape=torch.Size([2, 1]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.int64,\n",
      "        domain=discrete),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([2]))\n",
      "Reward Spec: Composite(\n",
      "    player_0: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_1: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_2: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_3: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([2, 1, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([2]))\n",
      "Done Spec: Composite(\n",
      "    done: Categorical(\n",
      "        shape=torch.Size([2, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    terminated: Categorical(\n",
      "        shape=torch.Size([2, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    truncated: Categorical(\n",
      "        shape=torch.Size([2, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    player_0: Composite(\n",
      "        done: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        terminated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        truncated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_1: Composite(\n",
      "        done: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        terminated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        truncated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_2: Composite(\n",
      "        done: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        terminated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        truncated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    player_3: Composite(\n",
      "        done: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        terminated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        truncated: Categorical(\n",
      "            shape=torch.Size([2, 1, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([2, 1])),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([2]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n",
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "Process _ProcessNoWarn-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/_utils.py\", line 734, in run\n",
      "    return mp.Process.run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py\", line 2163, in _run_worker_pipe_shared_mem\n",
      "    env = env_fun(**env_fun_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/env_creator.py\", line 203, in __call__\n",
      "    env = self.create_env_fn(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/utils.py\", line 254, in __call__\n",
      "    return self.fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_365912/662023212.py\", line 21, in <lambda>\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 1197, in __init__\n",
      "    t.set_container(self)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 525, in set_container\n",
      "    raise AttributeError(\n",
      "AttributeError: parent of transform <class 'torchrl.envs.transforms.transforms.RewardSum'> already set. Call `transform.clone()` to get a similar transform with no parent set.\n",
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n",
      "/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "Process _ProcessNoWarn-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/_utils.py\", line 734, in run\n",
      "    return mp.Process.run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py\", line 2163, in _run_worker_pipe_shared_mem\n",
      "    env = env_fun(**env_fun_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/env_creator.py\", line 203, in __call__\n",
      "    env = self.create_env_fn(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/data/utils.py\", line 254, in __call__\n",
      "    return self.fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_365912/662023212.py\", line 21, in <lambda>\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 1197, in __init__\n",
      "    t.set_container(self)\n",
      "  File \"/home/ubuntu/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py\", line 525, in set_container\n",
      "    raise AttributeError(\n",
      "AttributeError: parent of transform <class 'torchrl.envs.transforms.transforms.RewardSum'> already set. Call `transform.clone()` to get a similar transform with no parent set.\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEOFError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mReward Spec:\u001b[39m\u001b[33m\"\u001b[39m, env.reward_spec)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone Spec:\u001b[39m\u001b[33m\"\u001b[39m, env.done_spec)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mcheck_env_specs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/utils.py:733\u001b[39m, in \u001b[36mcheck_env_specs\u001b[39m\u001b[34m(env, return_contiguous, check_dtype, seed, tensordict)\u001b[39m\n\u001b[32m    731\u001b[39m     fake_tensordict = fake_tensordict.expand(shape)\n\u001b[32m    732\u001b[39m     tensordict = tensordict.expand(shape)\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m real_tensordict = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_contiguous\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_contiguous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n\u001b[32m    741\u001b[39m     fake_tensordict = fake_tensordict.unsqueeze(real_tensordict.batch_dims - \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/common.py:3115\u001b[39m, in \u001b[36mEnvBase.rollout\u001b[39m\u001b[34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[39m\n\u001b[32m   3112\u001b[39m env_device = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m   3114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_reset:\n\u001b[32m-> \u001b[39m\u001b[32m3115\u001b[39m     tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtensordict must be provided when auto_reset is False\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/common.py:2656\u001b[39m, in \u001b[36mEnvBase.reset\u001b[39m\u001b[34m(self, tensordict, **kwargs)\u001b[39m\n\u001b[32m   2652\u001b[39m     tensordict_reset = \u001b[38;5;28mself\u001b[39m._reset(\n\u001b[32m   2653\u001b[39m         tensordict.select(*\u001b[38;5;28mself\u001b[39m.reset_keys, strict=\u001b[38;5;28;01mFalse\u001b[39;00m), **kwargs\n\u001b[32m   2654\u001b[39m     )\n\u001b[32m   2655\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2656\u001b[39m     tensordict_reset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[38;5;66;03m# We assume that this is done properly\u001b[39;00m\n\u001b[32m   2658\u001b[39m \u001b[38;5;66;03m# if reset.device != self.device:\u001b[39;00m\n\u001b[32m   2659\u001b[39m \u001b[38;5;66;03m#     reset = reset.to(self.device, non_blocking=True)\u001b[39;00m\n\u001b[32m   2660\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict_reset \u001b[38;5;129;01mis\u001b[39;00m tensordict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py:63\u001b[39m, in \u001b[36m_check_start.<locals>.decorated_fun\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_closed:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_td()\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ParallelEnv):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_learning/venv/lib/python3.12/site-packages/torchrl/envs/batched_envs.py:1458\u001b[39m, in \u001b[36mParallelEnv._start_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28mself\u001b[39m._workers.append(process)\n\u001b[32m   1456\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m parent_pipe \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent_channels:\n\u001b[32m   1457\u001b[39m     \u001b[38;5;66;03m# use msg as sync point\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m     \u001b[43mparent_pipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1460\u001b[39m \u001b[38;5;66;03m# send shared tensordict to workers\u001b[39;00m\n\u001b[32m   1461\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent_channels:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:250\u001b[39m, in \u001b[36m_ConnectionBase.recv\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    249\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(buf.getbuffer())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:399\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m remaining == size:\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgot end of file during message\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mEOFError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"action_keys:\", env.action_keys)\n",
    "print(\"reward_keys:\", env.reward_keys)\n",
    "print(\"done_keys:\", env.done_keys)\n",
    "\n",
    "print(\"Action Spec:\", env.action_spec)\n",
    "print(\"Observation Spec:\", env.observation_spec)\n",
    "print(\"Reward Spec:\", env.reward_spec)\n",
    "print(\"Done Spec:\", env.done_spec)\n",
    "\n",
    "check_env_specs(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
